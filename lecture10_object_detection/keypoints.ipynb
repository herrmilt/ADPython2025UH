{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoint detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets detect a keypoint: the center of a circle.\n",
    "\n",
    "First, lets create a dataset containing proper images and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12091/4075550855.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return torch.tensor(data, device=device).unsqueeze(1), torch.tensor(labels, device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), torch.Size([2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 28\n",
    "\n",
    "class ShapesDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_size=28):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.data, self.labels = self.generate_data(num_samples, image_size)\n",
    "        \n",
    "    def generate_data(self, num_samples, image_size):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for _ in range(num_samples):\n",
    "            image = np.zeros((image_size, image_size), dtype=np.float32)\n",
    "            # Draw a circle\n",
    "            radius = np.random.randint(5, image_size // 4)\n",
    "            center_x = np.random.randint(radius, image_size - radius)\n",
    "            center_y = np.random.randint(radius, image_size - radius)\n",
    "            y, x = np.ogrid[:image_size, :image_size]\n",
    "            mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "            image[mask] = 1.0\n",
    "            data.append(image)\n",
    "            labels.append((center_y / image_size, center_x / image_size))\n",
    "        return torch.tensor(data, device=device).unsqueeze(1), torch.tensor(labels, device=device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create the dataset and dataloaders\n",
    "train_dataset = ShapesDataset(num_samples=1000, image_size=image_size)\n",
    "test_dataset = ShapesDataset(num_samples=200, image_size=image_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "train_dataset[0][0].shape, train_dataset[0][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    image, (cx, cy) = train_dataset[i]\n",
    "    cx = int(cx * image_size)\n",
    "    cy = int(cy * image_size)\n",
    "    to_show = image.squeeze().cpu().clone()\n",
    "    to_show[cx, cy] = 0.5\n",
    "    axes[i].imshow(to_show, cmap='gray')\n",
    "    # axes[i].set_title(f\"Label: {'Square' if label.item() == 0 else 'Circle'}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 980\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, \n",
    "                               kernel_size=6, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, \n",
    "                               padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.fc = nn.Linear(12 * 2 * 2, 2)  \n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.tanh(self.conv1(x)))\n",
    "        x = self.pool(self.tanh(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "torch.manual_seed(31416)\n",
    "\n",
    "print(\"Parameters:\", sum(p.nelement() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.03538635934353806\n",
      "Epoch [3/20], Loss: 0.0012970281866728328\n",
      "Epoch [5/20], Loss: 0.0005809482505719643\n",
      "Epoch [7/20], Loss: 0.00038555626961169767\n",
      "Epoch [9/20], Loss: 0.0002915487965219654\n",
      "Epoch [11/20], Loss: 0.0002513687434111489\n",
      "Epoch [13/20], Loss: 0.00020588459134160075\n",
      "Epoch [15/20], Loss: 0.0001833917741168989\n",
      "Epoch [17/20], Loss: 0.0001593273946127738\n",
      "Epoch [19/20], Loss: 0.00014500756908091716\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if epoch % (num_epochs // 10) == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"Training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00017%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_loss = []\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "print(f\"MSE: {np.mean(all_loss):.5f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    idx = torch.randint(0, len(test_dataset), (1,))\n",
    "    image, _ = test_dataset[idx.item()]\n",
    "    cx, cy = model(image.unsqueeze(0))[0]\n",
    "    cx = int(cx * image_size)\n",
    "    cy = int(cy * image_size)\n",
    "    to_show = image.squeeze().cpu().clone()\n",
    "    \n",
    "    to_show[cx, cy] = 0.5\n",
    "    axes[i].imshow(to_show, cmap='gray')\n",
    "    # axes[i].set_title(f\"Label: {'Square' if label.item() == 0 else 'Circle'}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More points to detect: square corners\n",
    "\n",
    "Now, we want to detect four keypoints per image: the corners of a square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), torch.Size([8]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 28\n",
    "\n",
    "class ShapesDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_size=28):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.data, self.labels = self.generate_data(num_samples, image_size)\n",
    "        \n",
    "    def generate_data(self, num_samples, image_size):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for _ in range(num_samples):\n",
    "            image = np.zeros((image_size, image_size), dtype=np.float32)\n",
    "            side = np.random.randint(5, image_size // 2)\n",
    "            top_left_x = np.random.randint(0, image_size - side)\n",
    "            top_left_y = np.random.randint(0, image_size - side)\n",
    "            image[top_left_x:top_left_x+side, top_left_y:top_left_y+side] = 1.0\n",
    "            data.append(image)\n",
    "            points = (\n",
    "                top_left_x, top_left_y, \n",
    "                top_left_x, top_left_y + side - 1,\n",
    "                top_left_x  + side - 1, top_left_y,\n",
    "                top_left_x  + side - 1, top_left_y + side - 1,\n",
    "            )\n",
    "            labels.append([p / image_size for p in points])\n",
    "        return torch.tensor(data, device=device).unsqueeze(1), torch.tensor(labels, device=device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create the dataset and dataloaders\n",
    "train_dataset = ShapesDataset(num_samples=1000, image_size=image_size)\n",
    "test_dataset = ShapesDataset(num_samples=200, image_size=image_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "train_dataset[0][0].shape, train_dataset[0][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    image, points = train_dataset[i]\n",
    "    to_show = image.squeeze().cpu().clone()\n",
    "    for px, py in points.view(-1, 2):\n",
    "        px = int(px * image_size)\n",
    "        py = int(py * image_size)\n",
    "        to_show[px, py] = 0.5\n",
    "    axes[i].imshow(to_show, cmap='gray')\n",
    "    # axes[i].set_title(f\"Label: {'Square' if label.item() == 0 else 'Circle'}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 1274\n"
     ]
    }
   ],
   "source": [
    "class SquareKPNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquareKPNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, \n",
    "                               kernel_size=6, padding=1, device=device)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, \n",
    "                               padding=1, device=device)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.fc = nn.Linear(12 * 2 * 2, 8, device=device)  # Adjust the dimensions accordingly\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.tanh(self.conv1(x)))\n",
    "        x = self.pool(self.tanh(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SquareKPNN()\n",
    "torch.manual_seed(31416)\n",
    "\n",
    "print(\"Parameters:\", sum(p.nelement() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.05900629230774939\n",
      "Epoch [3/20], Loss: 0.006242914057802409\n",
      "Epoch [5/20], Loss: 0.0037366604164708406\n",
      "Epoch [7/20], Loss: 0.0027753157197730615\n",
      "Epoch [9/20], Loss: 0.0020982961298432203\n",
      "Epoch [11/20], Loss: 0.0017554400867084042\n",
      "Epoch [13/20], Loss: 0.0015087698432034813\n",
      "Epoch [15/20], Loss: 0.001314693670719862\n",
      "Epoch [17/20], Loss: 0.0011642337802913972\n",
      "Epoch [19/20], Loss: 0.0010221840612939558\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if epoch % (num_epochs // 10) == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"Training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    idx = torch.randint(0, len(test_dataset), (1,))\n",
    "    image, _ = test_dataset[idx.item()]\n",
    "    points = model(image.unsqueeze(0))[0]\n",
    "    to_show = image.squeeze().cpu().clone()\n",
    "    for px, py in points.view(-1, 2):\n",
    "        px = int(px * image_size)\n",
    "        py = int(py * image_size)\n",
    "        to_show[px, py] = 0.5\n",
    "    axes[i].imshow(to_show, cmap='gray')\n",
    "    # axes[i].set_title(f\"Label: {'Square' if label.item() == 0 else 'Circle'}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
